/**
 * M√≥dulo de Servi√ßo de Voz - TarefoAI
 * 
 * Este servi√ßo gerencia a comunica√ß√£o por WebSockets para funcionalidades
 * relacionadas √† voz, incluindo:
 * 
 * 1. Transcri√ß√£o de √°udio enviado pelo cliente
 * 2. Processamento de comandos de voz pelo LLM
 * 3. S√≠ntese de fala para respostas
 * 4. Realiza√ß√£o de chamadas telef√¥nicas via Twilio
 */

import { Server as HttpServer } from 'http';
import { WebSocketServer, WebSocket } from 'ws';
import { Request, Response, Router } from 'express';
import twilio from 'twilio';
import { processText } from './llm-adapter';
import { storage } from './storage';

// Verifica se a configura√ß√£o necess√°ria para o servi√ßo de voz est√° dispon√≠vel
export function hasValidVoiceConfig(): boolean {
  return !!process.env.OPENAI_API_KEY; // Requisito m√≠nimo √© OpenAI para transcri√ß√£o/s√≠ntese
}

// Configura√ß√£o Twilio para chamadas telef√¥nicas
const twilioClient = process.env.TWILIO_ACCOUNT_SID && process.env.TWILIO_AUTH_TOKEN
  ? twilio(process.env.TWILIO_ACCOUNT_SID, process.env.TWILIO_AUTH_TOKEN)
  : null;

// Map para armazenar conex√µes por usu√°rio
const userConnections = new Map<number, WebSocket>();

// Rotas Express para status e configura√ß√£o do servi√ßo de voz
export const voiceRouter = Router();

// Verifica o status do servi√ßo de voz
voiceRouter.get('/status', (req: Request, res: Response) => {
  const twilioAvailable = !!twilioClient;
  const openaiAvailable = !!process.env.OPENAI_API_KEY;
  
  // Verifica a disponibilidade do servi√ßo
  const available = openaiAvailable; // Requisito m√≠nimo √© OpenAI para transcri√ß√£o/s√≠ntese
  
  let reason: string | undefined;
  if (!available) {
    if (!openaiAvailable) {
      reason = 'API OpenAI n√£o configurada. Para usar o assistente de voz, configure uma chave de API.';
    }
  }
  
  res.json({
    available,
    reason,
    features: {
      transcription: openaiAvailable,
      textToSpeech: openaiAvailable,
      phoneCalls: twilioAvailable
    }
  });
});

// Inicializa o servidor WebSocket para comunica√ß√£o de voz
export function setupVoiceServer(server: HttpServer) {
  // Configura√ß√£o do WebSocket Server
  const wss = new WebSocketServer({ 
    server,
    path: '/ws/voice'
  });
  
  console.log('Servidor WebSocket para servi√ßo de voz inicializado');
  
  wss.on('connection', async (ws: WebSocket) => {
    let userId: number | null = null;
    
    ws.on('message', async (message: any) => {
      try {
        // Primeira mensagem deve ser o ID do usu√°rio
        if (!userId) {
          try {
            const data = JSON.parse(message.toString());
            userId = data.userId;
            
            if (!userId) {
              sendError(ws, 'ID de usu√°rio n√£o fornecido');
              return;
            }
            
            // Verifica se o usu√°rio existe
            const user = await storage.getUser(userId);
            if (!user) {
              sendError(ws, 'Usu√°rio n√£o encontrado');
              return;
            }
            
            // Armazena a conex√£o associada ao usu√°rio
            userConnections.set(userId, ws);
            
            // Notifica o cliente sobre a conex√£o bem-sucedida
            ws.send(JSON.stringify({
              type: 'connection',
              connected: true,
              message: 'Conectado ao servi√ßo de voz'
            }));

            console.log(`üë§ Usu√°rio ${userId} conectado ao servi√ßo de voz`);
            return;
          } catch (error) {
            sendError(ws, 'Mensagem inicial inv√°lida, por favor forne√ßa um ID de usu√°rio');
            return;
          }
        }
        
        // Manipula comandos espec√≠ficos
        if (message instanceof Buffer) {
          // Processa √°udio recebido
          await handleAudioMessage(userId, message, ws);
        } else {
          // Processa mensagens JSON
          const messageStr = message.toString();
          
          try {
            const data = JSON.parse(messageStr);
            
            // Processamento de comandos especiais
            if (data.type === 'make_call') {
              await handleMakeCall(userId, data.phoneNumber, ws);
            }
          } catch (error) {
            console.error('Erro ao processar mensagem JSON:', error);
            sendError(ws, 'Formato de mensagem inv√°lido');
          }
        }
      } catch (error) {
        console.error('Erro ao processar mensagem do WebSocket:', error);
        sendError(ws, 'Erro interno do servidor');
      }
    });
    
    ws.on('close', () => {
      if (userId) {
        userConnections.delete(userId);
        console.log(`üë§ Usu√°rio ${userId} desconectado do servi√ßo de voz`);
      }
    });
  });
  
  console.log('üé§ Servi√ßo de voz AI inicializado com sucesso');
  
  return wss;
}

// Processa mensagens de √°udio
async function handleAudioMessage(userId: number, audioData: Buffer, ws: WebSocket) {
  try {
    // Simula transcri√ß√£o - em uma implementa√ß√£o real, enviaria para OpenAI Whisper
    // A transcri√ß√£o parcial √© fict√≠cia enquanto processa, e depois enviamos um resultado final
    
    sendStatus(ws, 'Processando √°udio...');
    
    // Simula uma transcri√ß√£o parcial (n√£o final)
    ws.send(JSON.stringify({
      type: 'transcription',
      text: 'Processando sua fala...',
      isFinal: false
    }));
    
    // Em uma implementa√ß√£o real, enviaria o √°udio para a API Whisper
    // Aqui, usamos um atraso para simular o processamento
    await new Promise(resolve => setTimeout(resolve, 1500));
    
    // A implementa√ß√£o abaixo simula a transcri√ß√£o e serve como estrutura para
    // quando a API real estiver conectada
    
    // Texto de exemplo de transcri√ß√£o
    const transcribedText = "Quais s√£o minhas tarefas para hoje?";
    
    // Envia a transcri√ß√£o final
    ws.send(JSON.stringify({
      type: 'transcription',
      text: transcribedText,
      isFinal: true
    }));
    
    // Processa a transcri√ß√£o com o LLM para obter resposta
    const aiResponse = await processText(userId, transcribedText);
    
    // Envia a resposta ao cliente
    ws.send(JSON.stringify({
      type: 'ai_response',
      text: aiResponse
    }));
    
    // Armazena a conversa no hist√≥rico
    await storage.createChatMessage({
      userId,
      role: 'user',
      content: transcribedText,
      timestamp: new Date()
    });
    
    await storage.createChatMessage({
      userId,
      role: 'assistant',
      content: aiResponse,
      timestamp: new Date()
    });
    
    // Em uma implementa√ß√£o real, enviaria o texto para a API de s√≠ntese de fala
    // e retornaria o √°udio para o cliente
    
  } catch (error) {
    console.error('Erro ao processar √°udio:', error);
    sendError(ws, 'Erro ao processar √°udio');
  }
}

// Faz uma chamada telef√¥nica via Twilio
async function handleMakeCall(userId: number, phoneNumber: string, ws: WebSocket) {
  if (!twilioClient) {
    sendCallStatus(ws, false, 'Servi√ßo de chamadas n√£o configurado', null);
    return;
  }
  
  try {
    // Formata o n√∫mero de telefone (adiciona +55 para Brasil se necess√°rio)
    if (!phoneNumber.startsWith('+')) {
      if (phoneNumber.startsWith('0')) {
        // Remove o 0 inicial e adiciona +55
        phoneNumber = '+55' + phoneNumber.substring(1);
      } else {
        // Adiciona c√≥digo do pa√≠s Brasil
        phoneNumber = '+55' + phoneNumber;
      }
    }
    
    // Remove caracteres n√£o num√©ricos (exceto o sinal de +)
    phoneNumber = '+' + phoneNumber.replace(/[^\d+]/g, '').substring(1);
    
    // Url da TwiML que deve responder quando a chamada for atendida
    const twimlUrl = `${process.env.PUBLIC_URL || 'http://localhost:5000'}/api/voice/twiml`;
    
    // Faz a chamada
    const call = await twilioClient.calls.create({
      to: phoneNumber,
      from: process.env.TWILIO_PHONE_NUMBER || '',
      url: twimlUrl,
    });
    
    // Notifica o cliente sobre o status da chamada
    sendCallStatus(ws, true, 'Chamada iniciada com sucesso', call.sid);
    
  } catch (error) {
    console.error('Erro ao fazer chamada:', error);
    sendCallStatus(ws, false, 'Erro ao fazer chamada: ' + (error instanceof Error ? error.message : 'Erro desconhecido'), null);
  }
}

// Fun√ß√µes auxiliares para enviar mensagens padronizadas ao cliente
function sendError(ws: WebSocket, message: string) {
  ws.send(JSON.stringify({
    type: 'error',
    message
  }));
}

function sendStatus(ws: WebSocket, message: string) {
  ws.send(JSON.stringify({
    type: 'status',
    message
  }));
}

function sendCallStatus(ws: WebSocket, success: boolean, message: string, callSid: string | null) {
  ws.send(JSON.stringify({
    type: 'call_status',
    success,
    message,
    callSid
  }));
}

// Rota para gerar resposta TwiML quando uma chamada √© atendida
voiceRouter.post('/twiml', (req: Request, res: Response) => {
  // Gera um documento TwiML b√°sico que diz uma mensagem quando a chamada for atendida
  const twiml = `
    <?xml version="1.0" encoding="UTF-8"?>
    <Response>
      <Say language="pt-BR">
        Ol√°, esta √© uma chamada de teste do TarefoAI. Obrigado por atender.
      </Say>
      <Pause length="1"/>
      <Say language="pt-BR">
        Esta chamada foi feita automaticamente atrav√©s da integra√ß√£o com Twilio.
        Tenha um √≥timo dia!
      </Say>
    </Response>
  `;
  
  res.type('text/xml');
  res.send(twiml);
});